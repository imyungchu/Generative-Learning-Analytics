{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p1agwGajo0tD",
    "outputId": "f93f96c7-10d1-46ae-ab29-f0c8ea7d60cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head: error.correction.csv: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error,pos,correction,error phrase,correct phrase,num of this error-correction phrase occur,num of this error-correction pair occur,collocation,category of collocation,total num of error time this error-correction pairs fall into this collocation category,unique num of error-correction pairs fall into this collocation category,total num of error occur\n",
      "make,VERB,do,make cooking,do cooking,10,1073,cooking,misc-ap-0,140,74,4016\n",
      "make,VERB,do,make washing,do washing,4,1073,washing,misc-ap-0,140,74,4016\n",
      "make,VERB,do,make cleaning,do cleaning,2,1073,cleaning,misc-ap-0,140,74,4016\n",
      "make,VERB,do,make homework,do homework,19,1073,homework,misc-ap-0,140,74,4016\n",
      "make,VERB,do,make classmate,do classmate,1,1073,classmate,misc-ap-0,140,74,4016\n",
      "make,VERB,do,make sunray,do sunray,1,1073,sunray,misc-ap-0,140,74,4016\n",
      "make,VERB,do,make pruning,do pruning,1,1073,pruning,misc-ap-0,140,74,4016\n",
      "make,VERB,do,make students'evaluation,do students'evaluation,1,1073,students'evaluation,misc-ap-0,140,74,4016\n",
      "make,VERB,do,make hawker,do hawker,2,1073,hawker,misc-ap-0,140,74,4016\n"
     ]
    }
   ],
   "source": [
    "! head error.correction.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "keIn4aGiu3IT"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('error.correction.csv', 'r', encoding='utf-8') as csvfile, \\\n",
    "     open('error.correction.txt', 'w', encoding='utf-8', newline='') as txtfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    writer = csv.writer(txtfile, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3XM2xkeJxeOb"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kP6lo2yMAOoE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sort: multi-character tab ‘$\\\\t’\n",
      "uniq: write error: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "! cut -d $'\\t' -f1,2,3,4,5,6,7,12 error.correction.txt | sort | uniq | sort -t $'\\t' -k8,8nr -k1,1 -k7,7nr -k6,6nr > ERR.sort.txt\n",
    "! sort -t $'\\t' -k1,1 -k4,4 -k6,6n ADJ.sort.txt | awk -F'\\t' '{if ($4 != prev) {print line;} line=$0; prev=$4;} END {print line;}' > ADJ.correction.long.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MnUe2qUmQv3z",
    "outputId": "5b6eca82-a713-448f-ac47-e75a49a9c458"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cut: the delimiter must be a single character\n",
      "Try 'cut --help' for more information.\n",
      "sort: multi-character tab ‘$\\\\t’\n",
      "sort: multi-character tab ‘$\\t’\n",
      "1 0 1 ADJ.correction.long.txt\n",
      "1 0 1 ADJ.correction.short.txt\n",
      "1 0 1 ADJ.correction.tiny.txt\n"
     ]
    }
   ],
   "source": [
    "# Process Replace Adjective Errors\n",
    "\n",
    "! grep $'\\tADJ\\t' error.correction.txt | cut -d $'\\t' -f1,2,3,4,5,6,7,12  | sort | uniq | sort -t $'\\t' -k8,8nr -k1,1 -k7,7nr -k6,6nr > ADJ.sort.txt\n",
    "! sort -t $'\\t' -k1,1 -k4,4 -k6,6n ADJ.sort.txt | awk -F'\\t' '{if ($4 != prev) {print line;} line=$0; prev=$4;} END {print line;}' > ADJ.correction.long.txt\n",
    "\n",
    "! grep -v $'\\t1\\t1\\t' ADJ.correction.long.txt > ADJ.correction.short.txt\n",
    "! grep -v $'\\t1\\t' ADJ.correction.long.txt > ADJ.correction.tiny.txt\n",
    "\n",
    "! egrep '(big cake|big amount)' ADJ.correction.long.txt\n",
    "!wc ADJ.correction.long.txt\n",
    "!wc ADJ.correction.short.txt\n",
    "!wc ADJ.correction.tiny.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Ky9miXxKTCW3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cut: the delimiter must be a single character\n",
      "Try 'cut --help' for more information.\n",
      "sort: multi-character tab ‘$\\\\t’\n",
      "sort: multi-character tab ‘$\\\\t’\n"
     ]
    }
   ],
   "source": [
    "# Process Replace Verb Errors\n",
    "! grep $'\\tVERB\\t' error.correction.txt | cut -d $'\\t' -f1,2,3,4,5,6,7,12  | sort | uniq | sort -t $'\\t' -k8,8nr -k1,1 -k7,7nr -k6,6nr > VERB.sort.txt\n",
    "! sort -t $'\\t' -k1,1 -k4,4 -k6,6n VERB.sort.txt | awk -F'\\t' '{if ($4 != prev) {print line;} line=$0; prev=$4;} END {print line;}' > VERB.correction.long.txt\n",
    "\n",
    "! grep -v $'\\t1\\t1\\t' VERB.correction.long.txt > VERB.correction.short.txt\n",
    "! grep -v $'\\t1\\t' VERB.correction.long.txt > VERB.correction.tiny.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zXT_B_pMVYzN",
    "outputId": "3f1aa3c3-ef50-47bd-9b3e-4d9a0930d67b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get\tVERB\tacquire\tget knowledge\tacquire knowledge\t12\t41\t3029\n",
      "make\tVERB\tdo\tmake homework\tdo homework\t19\t1073\t4016\n",
      "   18413  185498  977431 VERB.correction.long.txt\n",
      "   14240  142968  751887 VERB.correction.short.txt\n",
      "    4367   43818  230411 VERB.correction.tiny.txt\n"
     ]
    }
   ],
   "source": [
    "! egrep '(get knowledge|make homework)' VERB.correction.tiny.txt\n",
    "!wc VERB.correction.long.txt\n",
    "!wc VERB.correction.short.txt\n",
    "!wc VERB.correction.tiny.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "OJ_K8kGix60U"
   },
   "outputs": [],
   "source": [
    "# Process Replace NOUN Errors\n",
    "! grep $'\\tNOUN\\t' error.correction.txt | cut -d $'\\t' -f1,2,3,4,5,6,7,12  | sort | uniq | sort -t $'\\t' -k8,8nr -k1,1 -k7,7nr -k6,6nr > NOUN.sort.txt\n",
    "! sort -t $'\\t' -k1,1 -k4,4 -k6,6n NOUN.sort.txt | awk -F'\\t' '{if ($4 != prev) {print line;} line=$0; prev=$4;} END {print line;}' > NOUN.correction.long.txt\n",
    "\n",
    "! grep -v $'\\t1\\t1\\t' NOUN.correction.long.txt > NOUN.correction.short.txt\n",
    "! grep -v $'\\t1\\t' NOUN.correction.long.txt > NOUN.correction.tiny.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ReV4h3kgyNyK",
    "outputId": "65c0656a-1e8d-4b72-a667-2fde3c14e9f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Govt\tNOUN\tgovernment\tGovt japanese\tgovernment japanese\t3\t2\t2\n",
      "ability\tNOUN\tskill\tability english\tskill english\t52\t63\t85\n",
      "ability\tNOUN\tskill\tability enough\tskill enough\t2\t63\t85\n",
      "ability\tNOUN\tsituation\tability financial\tsituation financial\t2\t2\t85\n",
      "ability\tNOUN\tskill\tability good\tskill good\t3\t63\t85\n",
      "ability\tNOUN\tlevel\tability high\tlevel high\t3\t7\t85\n",
      "ability\tNOUN\tskill\tability japanese\tskill japanese\t4\t63\t85\n",
      "ability\tNOUN\tskill\tability more\tskill more\t2\t63\t85\n",
      "ability\tNOUN\tskill\tability poor\tskill poor\t2\t63\t85\n",
      "    9825  100480  563364 NOUN.correction.long.txt\n",
      "    6352   64396  358290 NOUN.correction.short.txt\n",
      "    1776   18012  100080 NOUN.correction.tiny.txt\n"
     ]
    }
   ],
   "source": [
    "! head NOUN.correction.tiny.txt\n",
    "! egrep '(get knowledge|make homework)' NOUN.correction.tiny.txt\n",
    "!wc NOUN.correction.long.txt\n",
    "!wc NOUN.correction.short.txt\n",
    "!wc NOUN.correction.tiny.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "vH1FKo21zQHN"
   },
   "outputs": [],
   "source": [
    "# Process Replace ADVERB Errors\n",
    "! grep $'\\tADV\\t' error.correction.txt | cut -d $'\\t' -f1,2,3,4,5,6,7,12  | sort | uniq | sort -t $'\\t' -k8,8nr -k1,1 -k7,7nr -k6,6nr > ADV.sort.txt\n",
    "! sort -t $'\\t' -k1,1 -k4,4 -k6,6n ADV.sort.txt | awk -F'\\t' '{if ($4 != prev) {print line;} line=$0; prev=$4;} END {print line;}' > ADV.correction.long.txt\n",
    "\n",
    "! grep -v $'\\t1\\t1\\t' ADV.correction.long.txt > ADV.correction.short.txt\n",
    "! grep -v $'\\t1\\t' ADV.correction.long.txt > ADV.correction.tiny.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Vk5S3aUzdaz",
    "outputId": "1d8868ce-123c-4245-f37d-4653d0db82fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "about\tADV\tapproximately\tabout 6\tapproximately 6\t2\t5\t21\n",
      "about\tADV\tdiscuss\tabout topic\tdiscuss topic\t2\t2\t21\n",
      "abroad\tADV\tforeign\tabroad people\tforeign people\t2\t2\t6\n",
      "absolutely\tADV\tdefinitely\tabsolutely be\tdefinitely be\t16\t31\t99\n",
      "absolutely\tADV\tcompletely\tabsolutely change\tcompletely change\t3\t44\t99\n",
      "absolutely\tADV\tcompletely\tabsolutely different\tcompletely different\t3\t44\t99\n",
      "absolutely\tADV\tcompletely\tabsolutely empty\tcompletely empty\t2\t44\t99\n",
      "absolutely\tADV\tdefinitely\tabsolutely find\tdefinitely find\t2\t31\t99\n",
      "absolutely\tADV\tdefinitely\tabsolutely go\tdefinitely go\t4\t31\t99\n",
      "    6324   64010  342753 ADV.correction.long.txt\n",
      "    5056   51020  270476 ADV.correction.short.txt\n",
      "    1595   16098   84051 ADV.correction.tiny.txt\n"
     ]
    }
   ],
   "source": [
    "! head ADV.correction.tiny.txt\n",
    "! egrep '(get knowledge|make homework)' ADV.correction.tiny.txt\n",
    "!wc ADV.correction.long.txt\n",
    "!wc ADV.correction.short.txt\n",
    "!wc ADV.correction.tiny.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sjw6BSEazqKE",
    "outputId": "327999da-364a-4da3-c6bd-2ddd40d2a3ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36656 VERB\n",
      "17078 NOUN\n",
      "13404 ADV\n",
      "12396 ADJ\n",
      "3607 AUX\n",
      "2461 PROPN\n",
      "1184 ADP\n",
      " 625 PART\n",
      " 428 INTJ\n",
      " 403 SCONJ\n",
      " 388 PRON\n",
      " 237 NUM\n",
      " 138 PUNCT\n",
      "  87 X\n",
      "  20 CCONJ\n",
      "  14 DET\n",
      "  12 SPACE\n",
      "   1 pos\n"
     ]
    }
   ],
   "source": [
    "! cut -d $'\\t' -f2 error.correction.txt | sort | uniq -c | sort -nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jaMZwECG2Nj6",
    "outputId": "747496fa-71ac-4480-f808-68d1046d5909"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "big\tADJ\tlarge\tbig amount\tlarge amount\t35\t123\t500\n",
      "big\tADJ\tlarge\tbig cake\tlarge cake\t4\t123\t500\n",
      "ability\tNOUN\tskill\tability english\tskill english\t52\t63\t85\n",
      "capability\tNOUN\tskill\tcapability english\tskill english\t6\t15\t68\n",
      "learn\tVERB\tacquire\tlearn knowledge\tacquire knowledge\t53\t131\t473\n",
      "make\tVERB\tdo\tmake homework\tdo homework\t19\t1073\t4016\n",
      "   40871  413330 2244699 ALL.errata.txt\n",
      "   30517  307166 1657656 ALL.errata.short.txt\n",
      "    9453   95114  512866 ALL.errata.tiny.txt\n"
     ]
    }
   ],
   "source": [
    "# Process Replace ALL pos Errors\n",
    "\n",
    "! egrep $'\\t(ADJ|VERB|NOUN|ADV)\\t' error.correction.txt | grep -v '\\-\\-\\-' > temp1.txt\n",
    "\n",
    "! cut -d $'\\t' -f1,2,3,4,5,6,7,12 temp1.txt | sort | uniq | sort -t $'\\t' -k8,8nr -k1,1 -k7,7nr -k6,6nr > temp2.txt\n",
    "\n",
    "! sort -t $'\\t' -k2,2 -k1,1 -k4,4 -k6,6n temp2.txt | awk -F'\\t' '{if ($4 != prev) {print line;} line=$0; prev=$4;} END {print line;}' > ALL.errata.txt\n",
    "\n",
    "! egrep '(big cake|big amount|make homework|learn knowledge|ability english)' ALL.errata.txt | head\n",
    "\n",
    "! grep -v $'\\t1\\t1\\t' ALL.errata.txt > ALL.errata.short.txt\n",
    "! grep -v $'\\t1\\t' ALL.errata.txt > ALL.errata.tiny.txt\n",
    "! wc ALL.errata.txt\n",
    "! wc ALL.errata.short.txt\n",
    "! wc ALL.errata.tiny.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uiJcSEFKTpQ6",
    "outputId": "ab191333-db70-4212-a161-498f8eafd309"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\tADJ\tcurrent\tactual buthhouse\tcurrent buthhouse\t1\t44\t57\n",
      "big\tADJ\tlarge\tbig amount\tlarge amount\t35\t123\t500\n",
      "big\tADJ\tlarge\tbig cake\tlarge cake\t4\t123\t500\n",
      "ability\tNOUN\tskill\tability english\tskill english\t52\t63\t85\n",
      "capability\tNOUN\tskill\tcapability english\tskill english\t6\t15\t68\n",
      "learn\tVERB\tacquire\tlearn knowledge\tacquire knowledge\t53\t131\t473\n",
      "make\tVERB\tdo\tmake homework\tdo homework\t19\t1073\t4016\n"
     ]
    }
   ],
   "source": [
    "! egrep \"(big cake|big amount|make homework|learn knowledge|ability english|buthhouse|farmer'sincome)\" ALL.errata.short.txt | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3hurNOyOAjs8",
    "outputId": "bb6ba918-00f7-491b-e263-d54d851f7e51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acquire\tV:obj:N\tknowledge\t12\n",
      "acquired\t-N:mod:A\tknowledge\t2\n"
     ]
    }
   ],
   "source": [
    "! egrep 'acquire.*knowledge' mp.lexcoll.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Om-oC4GlA3Qm",
    "outputId": "5280442d-4ccb-49d4-da8d-6b833f39bad5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "egrep: mp.deps.sort.txt: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "! egrep -- $'-N:mod:A\\train\\t' mp.deps.sort.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "htW1OXwP_qme"
   },
   "outputs": [],
   "source": [
    "# build a dictionary of collocation\n",
    "collcount = [ line.strip().split('\\t') for line in open('mp.lexcoll.txt').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PSZhCTZ2AYdX",
    "outputId": "66d378cb-d71b-41b5-a9e8-9077e7e42e8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['he', '-V:subj:N', 'say', '46684'], ['last', '-N:mod:A', 'year', '36022'], ['I', '-V:subj:N', 'think', '34122'], ['we', '-V:subj:N', 'have', '29380'], ['it', '-V:subj:N', 'have', '21738']]\n"
     ]
    }
   ],
   "source": [
    "print(collcount[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "bHWygpzFAtMm"
   },
   "outputs": [],
   "source": [
    "colldict = dict( [((dep[0]+' '+dep[2]).lower(), int(dep[3])) for dep in collcount if dep[3].isdigit() ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xIupT0WpBOGQ",
    "outputId": "b7509863-0fd6-4f8a-92ac-b3c73e5d9d55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found\n"
     ]
    }
   ],
   "source": [
    "print(colldict['valuable logo'] if 'valuable logo' in colldict else 'not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error</th>\n",
       "      <th>pos</th>\n",
       "      <th>correction</th>\n",
       "      <th>error phrase</th>\n",
       "      <th>correct phrase</th>\n",
       "      <th>num of this error-correction phrase occur</th>\n",
       "      <th>num of this error-correction pair occur</th>\n",
       "      <th>collocation</th>\n",
       "      <th>category of collocation</th>\n",
       "      <th>total num of error time this error-correction pairs fall into this collocation category</th>\n",
       "      <th>unique num of error-correction pairs fall into this collocation category</th>\n",
       "      <th>total num of error occur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>make</td>\n",
       "      <td>VERB</td>\n",
       "      <td>do</td>\n",
       "      <td>make cooking</td>\n",
       "      <td>do cooking</td>\n",
       "      <td>10</td>\n",
       "      <td>1073</td>\n",
       "      <td>cooking</td>\n",
       "      <td>misc-ap-0</td>\n",
       "      <td>140</td>\n",
       "      <td>74</td>\n",
       "      <td>4016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>make</td>\n",
       "      <td>VERB</td>\n",
       "      <td>do</td>\n",
       "      <td>make washing</td>\n",
       "      <td>do washing</td>\n",
       "      <td>4</td>\n",
       "      <td>1073</td>\n",
       "      <td>washing</td>\n",
       "      <td>misc-ap-0</td>\n",
       "      <td>140</td>\n",
       "      <td>74</td>\n",
       "      <td>4016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>make</td>\n",
       "      <td>VERB</td>\n",
       "      <td>do</td>\n",
       "      <td>make cleaning</td>\n",
       "      <td>do cleaning</td>\n",
       "      <td>2</td>\n",
       "      <td>1073</td>\n",
       "      <td>cleaning</td>\n",
       "      <td>misc-ap-0</td>\n",
       "      <td>140</td>\n",
       "      <td>74</td>\n",
       "      <td>4016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>make</td>\n",
       "      <td>VERB</td>\n",
       "      <td>do</td>\n",
       "      <td>make homework</td>\n",
       "      <td>do homework</td>\n",
       "      <td>19</td>\n",
       "      <td>1073</td>\n",
       "      <td>homework</td>\n",
       "      <td>misc-ap-0</td>\n",
       "      <td>140</td>\n",
       "      <td>74</td>\n",
       "      <td>4016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>make</td>\n",
       "      <td>VERB</td>\n",
       "      <td>do</td>\n",
       "      <td>make classmate</td>\n",
       "      <td>do classmate</td>\n",
       "      <td>1</td>\n",
       "      <td>1073</td>\n",
       "      <td>classmate</td>\n",
       "      <td>misc-ap-0</td>\n",
       "      <td>140</td>\n",
       "      <td>74</td>\n",
       "      <td>4016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  error   pos correction    error phrase correct phrase  \\\n",
       "0  make  VERB         do    make cooking     do cooking   \n",
       "1  make  VERB         do    make washing     do washing   \n",
       "2  make  VERB         do   make cleaning    do cleaning   \n",
       "3  make  VERB         do   make homework    do homework   \n",
       "4  make  VERB         do  make classmate   do classmate   \n",
       "\n",
       "   num of this error-correction phrase occur  \\\n",
       "0                                         10   \n",
       "1                                          4   \n",
       "2                                          2   \n",
       "3                                         19   \n",
       "4                                          1   \n",
       "\n",
       "   num of this error-correction pair occur collocation  \\\n",
       "0                                     1073     cooking   \n",
       "1                                     1073     washing   \n",
       "2                                     1073    cleaning   \n",
       "3                                     1073    homework   \n",
       "4                                     1073   classmate   \n",
       "\n",
       "  category of collocation  \\\n",
       "0               misc-ap-0   \n",
       "1               misc-ap-0   \n",
       "2               misc-ap-0   \n",
       "3               misc-ap-0   \n",
       "4               misc-ap-0   \n",
       "\n",
       "   total num of error time this error-correction pairs fall into this collocation category  \\\n",
       "0                                                140                                         \n",
       "1                                                140                                         \n",
       "2                                                140                                         \n",
       "3                                                140                                         \n",
       "4                                                140                                         \n",
       "\n",
       "   unique num of error-correction pairs fall into this collocation category  \\\n",
       "0                                                 74                          \n",
       "1                                                 74                          \n",
       "2                                                 74                          \n",
       "3                                                 74                          \n",
       "4                                                 74                          \n",
       "\n",
       "   total num of error occur  \n",
       "0                      4016  \n",
       "1                      4016  \n",
       "2                      4016  \n",
       "3                      4016  \n",
       "4                      4016  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/error.correction.csv', sep=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error</th>\n",
       "      <th>pos</th>\n",
       "      <th>correction</th>\n",
       "      <th>error phrase</th>\n",
       "      <th>correct phrase</th>\n",
       "      <th>num of this error-correction phrase occur</th>\n",
       "      <th>num of this error-correction pair occur</th>\n",
       "      <th>collocation</th>\n",
       "      <th>category of collocation</th>\n",
       "      <th>total num of error time this error-correction pairs fall into this collocation category</th>\n",
       "      <th>unique num of error-correction pairs fall into this collocation category</th>\n",
       "      <th>total num of error occur</th>\n",
       "      <th>error_collocation</th>\n",
       "      <th>correction_collocation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>make</td>\n",
       "      <td>VERB</td>\n",
       "      <td>do</td>\n",
       "      <td>make cooking</td>\n",
       "      <td>do cooking</td>\n",
       "      <td>10</td>\n",
       "      <td>1073</td>\n",
       "      <td>cooking</td>\n",
       "      <td>misc-ap-0</td>\n",
       "      <td>140</td>\n",
       "      <td>74</td>\n",
       "      <td>4016</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>make</td>\n",
       "      <td>VERB</td>\n",
       "      <td>do</td>\n",
       "      <td>make washing</td>\n",
       "      <td>do washing</td>\n",
       "      <td>4</td>\n",
       "      <td>1073</td>\n",
       "      <td>washing</td>\n",
       "      <td>misc-ap-0</td>\n",
       "      <td>140</td>\n",
       "      <td>74</td>\n",
       "      <td>4016</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>make</td>\n",
       "      <td>VERB</td>\n",
       "      <td>do</td>\n",
       "      <td>make cleaning</td>\n",
       "      <td>do cleaning</td>\n",
       "      <td>2</td>\n",
       "      <td>1073</td>\n",
       "      <td>cleaning</td>\n",
       "      <td>misc-ap-0</td>\n",
       "      <td>140</td>\n",
       "      <td>74</td>\n",
       "      <td>4016</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>make</td>\n",
       "      <td>VERB</td>\n",
       "      <td>do</td>\n",
       "      <td>make homework</td>\n",
       "      <td>do homework</td>\n",
       "      <td>19</td>\n",
       "      <td>1073</td>\n",
       "      <td>homework</td>\n",
       "      <td>misc-ap-0</td>\n",
       "      <td>140</td>\n",
       "      <td>74</td>\n",
       "      <td>4016</td>\n",
       "      <td>0</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>make</td>\n",
       "      <td>VERB</td>\n",
       "      <td>do</td>\n",
       "      <td>make classmate</td>\n",
       "      <td>do classmate</td>\n",
       "      <td>1</td>\n",
       "      <td>1073</td>\n",
       "      <td>classmate</td>\n",
       "      <td>misc-ap-0</td>\n",
       "      <td>140</td>\n",
       "      <td>74</td>\n",
       "      <td>4016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  error   pos correction    error phrase correct phrase  \\\n",
       "0  make  VERB         do    make cooking     do cooking   \n",
       "1  make  VERB         do    make washing     do washing   \n",
       "2  make  VERB         do   make cleaning    do cleaning   \n",
       "3  make  VERB         do   make homework    do homework   \n",
       "4  make  VERB         do  make classmate   do classmate   \n",
       "\n",
       "   num of this error-correction phrase occur  \\\n",
       "0                                         10   \n",
       "1                                          4   \n",
       "2                                          2   \n",
       "3                                         19   \n",
       "4                                          1   \n",
       "\n",
       "   num of this error-correction pair occur collocation  \\\n",
       "0                                     1073     cooking   \n",
       "1                                     1073     washing   \n",
       "2                                     1073    cleaning   \n",
       "3                                     1073    homework   \n",
       "4                                     1073   classmate   \n",
       "\n",
       "  category of collocation  \\\n",
       "0               misc-ap-0   \n",
       "1               misc-ap-0   \n",
       "2               misc-ap-0   \n",
       "3               misc-ap-0   \n",
       "4               misc-ap-0   \n",
       "\n",
       "   total num of error time this error-correction pairs fall into this collocation category  \\\n",
       "0                                                140                                         \n",
       "1                                                140                                         \n",
       "2                                                140                                         \n",
       "3                                                140                                         \n",
       "4                                                140                                         \n",
       "\n",
       "   unique num of error-correction pairs fall into this collocation category  \\\n",
       "0                                                 74                          \n",
       "1                                                 74                          \n",
       "2                                                 74                          \n",
       "3                                                 74                          \n",
       "4                                                 74                          \n",
       "\n",
       "   total num of error occur  error_collocation  correction_collocation  \n",
       "0                      4016                  3                      39  \n",
       "1                      4016                  0                       4  \n",
       "2                      4016                  0                      12  \n",
       "3                      4016                  0                     229  \n",
       "4                      4016                  0                       0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each row, count the error phrase and correction phrase in the collocation dictionary\n",
    "def count_collocation(row):\n",
    "    error_phrase = row['error phrase'].lower()\n",
    "    correction_phrase = row['correct phrase'].lower()\n",
    "    return colldict.get(error_phrase, 0), colldict.get(correction_phrase, 0)\n",
    "df[['error_collocation', 'correction_collocation']] = df.apply(count_collocation, axis=1, result_type='expand')\n",
    "df.head()\n",
    "# if the error phrase is larger than the correction phrase, delete the row from the DataFrame\n",
    "df = df[df['error_collocation'] <= df['correction_collocation']]\n",
    "# if the pos not ADJ, VERB, NOUN, or ADV, delete the row from the DataFrame\n",
    "df = df[df['pos'].isin(['ADJ', 'VERB', 'NOUN', 'ADV'])]\n",
    "\n",
    "# save the updated DataFrame to a new CSV file\n",
    "df.to_csv('data/error.correction.collocation.csv', index=False)\n",
    "# Display the first few rows of the updated DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV\n",
    "df = pd.read_csv('data/error.correction.collocation.csv')\n",
    "\n",
    "# For each collocation, keep the row with the largest 'unique num of error-correction pairs fall into this collocation category'\n",
    "df_sorted = df.sort_values(\n",
    "    'unique num of error-correction pairs fall into this collocation category',\n",
    "    ascending=False\n",
    ")\n",
    "\n",
    "# Drop duplicates, keeping the first (which is the largest due to sorting)\n",
    "result = df_sorted.drop_duplicates(subset=['collocation', 'error phrase', 'correct phrase'])\n",
    "\n",
    "# Optional: Reset index\n",
    "result = result.reset_index(drop=True)\n",
    "\n",
    "# Save or use result\n",
    "result.to_csv('data/disambiguated_collocations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "auRdxJdnu49t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['error', 'pos', 'correction', 'error phrase', 'correct phrase', 'num of this error-correction phrase occur', 'num of this error-correction pair occur', 'collocation', 'category of collocation', 'total num of error time this error-correction pairs fall into this collocation category', 'unique num of error-correction pairs fall into this collocation category', 'total num of error occur']\n"
     ]
    }
   ],
   "source": [
    "# erratalist = [line.strip().split('\\t') for lines in open('error.correction.txt').readlines() ]\n",
    "\n",
    "for line in open('error.correction.txt').readlines():\n",
    "  print(line.strip().split('\\t'))\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "2zdnKlg3vWMx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['error', 'pos', 'correction', 'error phrase', 'correct phrase', 'num of this error-correction phrase occur', 'num of this error-correction pair occur', 'collocation', 'category of collocation', 'total num of error time this error-correction pairs fall into this collocation category', 'unique num of error-correction pairs fall into this collocation category', 'total num of error occur']\n"
     ]
    }
   ],
   "source": [
    "# erratalist = [line.strip().split('\\t') for lines in open('error.correction.txt').readlines() ]\n",
    "\n",
    "for line in open('error.correction.txt').readlines():\n",
    "  print(line.strip().split('\\t'))\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "apXH4W7nxRup"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['error', 'pos', 'correction', 'error phrase', 'correct phrase', 'num of this error-correction phrase occur', 'num of this error-correction pair occur', 'collocation', 'category of collocation', 'total num of error time this error-correction pairs fall into this collocation category', 'unique num of error-correction pairs fall into this collocation category', 'total num of error occur']\n"
     ]
    }
   ],
   "source": [
    "erratalist = [line.strip().split('\\t') for line in open('error.correction.txt').readlines() ]\n",
    "\n",
    "for line in open('error.correction.txt').readlines():\n",
    "    print(line.strip().split('\\t'))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, _, _, errorphrase, correctphrase, _, _, _, _, _, _, _ in erratalist:\n",
    "    ecount = colldict[errorphrase] if errorphrase in colldict else 0\n",
    "    ccount = colldict[correctphrase] if correctphrase in colldict else 0\n",
    "    print (errorphrase, ecount, correctphrase, ccount)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
